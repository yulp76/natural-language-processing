{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import urllib\n",
    "import re\n",
    "import string\n",
    "import copy\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urllib.request.urlopen(\"https://s3.us-east-2.amazonaws.com/yulp-public/sst3.train.txt\") as f1:\n",
    "    train = f1.read().decode('utf-8').splitlines()\n",
    "\n",
    "with urllib.request.urlopen(\"https://s3.us-east-2.amazonaws.com/yulp-public/sst3.dev.txt\") as f2:\n",
    "    dev = f2.read().decode('utf-8').splitlines()\n",
    "    \n",
    "with urllib.request.urlopen(\"https://s3.us-east-2.amazonaws.com/yulp-public/sst3.devtest.txt\") as f3:\n",
    "    devtest = f3.read().decode('utf-8').splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"0\", \"1\", \"2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = nltk.pos_tag(tokens)\n",
    "    lm = WordNetLemmatizer()\n",
    "    \n",
    "    def get_category(token):\n",
    "        tag = token[1]\n",
    "        if tag.startswith('N'):\n",
    "            return 'n'\n",
    "        elif tag.startswith('V'):\n",
    "            return 'v'\n",
    "        elif tag.startswith('J'):\n",
    "            return 'a'\n",
    "        elif tag.startswith('R'):\n",
    "            return 'r'\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    lemmatized_tokens = [lm.lemmatize(token[0], get_category(token))\n",
    "                         if get_category(token)\n",
    "                         else token[0]\n",
    "                         for token in tokens]\n",
    "    \n",
    "    lemmatized_text = ' '.join(lemmatized_tokens)\n",
    "    return lemmatized_text\n",
    "\n",
    "\n",
    "def remove_punctuations_and_stopwords(text):\n",
    "    pattern = re.compile('[{}]'.format(re.escape(string.punctuation)))\n",
    "    text = pattern.sub('', text)\n",
    "\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stopword_list = nltk.corpus.stopwords.words('english')\n",
    "    tokens = [token for token in tokens if token not in stopword_list]\n",
    "    text = ' '.join(tokens)\n",
    "       \n",
    "    return text\n",
    "\n",
    "def normalize(text):\n",
    "    text = text.lower()\n",
    "    text = lemmatize(text)\n",
    "    text = remove_punctuations_and_stopwords(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(corpus, feature=\"ub\"):\n",
    "    lst = []\n",
    "    \n",
    "    for entry in corpus:\n",
    "        [text, label] = entry.split(\"\\t\")\n",
    "        \n",
    "        if feature == \"normalized\":\n",
    "            text = normalize(text)\n",
    "        \n",
    "        tokens = nltk.word_tokenize(text)\n",
    "            \n",
    "        if feature == \"bb\":       \n",
    "            tokens = list(nltk.bigrams(tokens))\n",
    "            \n",
    "        lst.append((tokens, label))\n",
    "                          \n",
    "    return lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(corpus_lst):\n",
    "    features = {}\n",
    "    for entry in corpus_lst:\n",
    "        label = entry[1]\n",
    "        for item in entry[0]:\n",
    "            if features.get(item) is None:\n",
    "                features[item] = {}\n",
    "            if features[item].get(label) is None:\n",
    "                features[item][label] = 0.0\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(entry, features, labels, hinge=False):\n",
    "    max_score = float(\"-inf\")\n",
    "    (tokens, gs) = entry\n",
    "    \n",
    "    for label in labels:\n",
    "        score = 0.0\n",
    "        \n",
    "        for token in tokens:\n",
    "            d = features.get(token)\n",
    "            if d is not None:\n",
    "                score += d.get(label, 0)\n",
    "        \n",
    "        if hinge:\n",
    "            if label != gs:\n",
    "                score += 1\n",
    "                \n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            prediction = label\n",
    "            \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(test_lst, features, labels):\n",
    "    n = len(test_lst)\n",
    "    correct = 0\n",
    "    for entry in test_lst:\n",
    "        prediction = classify(entry, features, labels)\n",
    "        if prediction == entry[1]:\n",
    "            correct += 1\n",
    "    return correct/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_training(train_lst, dev_lst, devtest_lst, features, labels, ss=0.01, epoch=20, hinge=False):\n",
    "    features_ = copy.deepcopy(features)\n",
    "    best_accuracy = 0\n",
    "    n = len(train_lst)\n",
    "    \n",
    "    for e in range(epoch):\n",
    "        print(\"Epoch \"+str(e+1)+\":\")\n",
    "        counter = 0\n",
    "        \n",
    "        for entry in train_lst:\n",
    "            counter += 1\n",
    "            (tokens, gs) = entry\n",
    "            \n",
    "            if hinge:\n",
    "                prediction = classify(entry, features_, labels, hinge=True)\n",
    "            else:\n",
    "                prediction = classify(entry, features_, labels)\n",
    "            \n",
    "            if prediction != gs:\n",
    "                for token in tokens:\n",
    "                    d = features_[token]\n",
    "                    if d.get(gs) is not None:\n",
    "                        d[gs] += ss\n",
    "                    if d.get(prediction) is not None:\n",
    "                        d[prediction] -= ss\n",
    "            \n",
    "            if counter%20000 == 0 or counter == n:\n",
    "                print(\"\\t\"+str(counter)+\" examples trained:\")\n",
    "                accuracy = test_accuracy(dev_lst, features_, labels)\n",
    "                print(\"\\t\\t\"+\"Accurary on DEV: \"+str(accuracy))\n",
    "                if accuracy > best_accuracy:\n",
    "                    features_best_weight = copy.deepcopy(features_)\n",
    "                    best_accuracy = accuracy\n",
    "                    accuracy_devtest = test_accuracy(devtest_lst, features_, labels)\n",
    "                    print(\"\\t\\t\"+\"Accurary on DEVTEST: \"+str(accuracy_devtest))\n",
    "    \n",
    "    return features_best_weight, best_accuracy, accuracy_devtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature weight analyis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_analysis(features, labels):\n",
    "    weights = {label:[] for label in labels}\n",
    "    \n",
    "    for token, d in features.items():\n",
    "        for label, weight in d.items():\n",
    "            weights[label].append((weight, token))\n",
    "    \n",
    "    for label in labels:\n",
    "        print(\"Label \"+label+\":\")\n",
    "        weights[label].sort(reverse=True)\n",
    "        print(\"\\tTop 10 features:\")\n",
    "        for feature in weights[label][:10]:\n",
    "            print(\"\\t\\t\"+str(feature[1])+\": \" + \"{0:.2f}\".format(feature[0]))\n",
    "        print(\"\\tBottom 10 features:\")\n",
    "        for feature in list(reversed(weights[label][-10:])):\n",
    "            print(\"\\t\\t\"+str(feature[1])+\": \" + \"{0:.2f}\".format(feature[0]))\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_analysis(test_lst, test_corpus, features, labels):\n",
    "    for i, entry in enumerate(test_lst):\n",
    "        prediction = classify(entry, features, labels)\n",
    "        if prediction != entry[1]:\n",
    "            print(\"Sentence: \"+test_corpus[i].split(\"\\t\")[0])\n",
    "            print(\"Gold Standard: \"+entry[1])\n",
    "            print(\"Prediction: \"+prediction)\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lst = preprocess(train)\n",
    "dev_lst = preprocess(dev)\n",
    "devtest_lst = preprocess(devtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_0 = extract_features(train_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.4672727272727273\n",
      "\t\tAccurary on DEVTEST: 0.47005444646098005\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.49272727272727274\n",
      "\t\tAccurary on DEVTEST: 0.4482758620689655\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5\n",
      "\t\tAccurary on DEVTEST: 0.4627949183303085\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.46545454545454545\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5527272727272727\n",
      "\t\tAccurary on DEVTEST: 0.5190562613430127\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5909090909090909\n",
      "\t\tAccurary on DEVTEST: 0.5226860254083484\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.5545454545454546\n",
      "Epoch 2:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.49636363636363634\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.49818181818181817\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5454545454545454\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5690909090909091\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5563636363636364\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5836363636363636\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.5618181818181818\n",
      "Epoch 3:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5709090909090909\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5127272727272727\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5454545454545454\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5709090909090909\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5854545454545454\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6363636363636364\n",
      "\t\tAccurary on DEVTEST: 0.5716878402903811\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6181818181818182\n",
      "Epoch 4:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5363636363636364\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5145454545454545\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5909090909090909\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5036363636363637\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.52\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6363636363636364\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.5854545454545454\n",
      "Epoch 5:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.43454545454545457\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5036363636363637\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5890909090909091\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5218181818181818\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5163636363636364\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6418181818181818\n",
      "\t\tAccurary on DEVTEST: 0.5716878402903811\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6\n",
      "Epoch 6:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5618181818181818\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5145454545454545\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6036363636363636\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5563636363636364\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.4890909090909091\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6090909090909091\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.5963636363636363\n",
      "Epoch 7:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5381818181818182\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.49272727272727274\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5636363636363636\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5072727272727273\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5345454545454545\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6145454545454545\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.5872727272727273\n",
      "Epoch 8:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.43636363636363634\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5054545454545455\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5781818181818181\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5327272727272727\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5672727272727273\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6163636363636363\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.610909090909091\n",
      "Epoch 9:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.47454545454545455\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5236363636363637\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5581818181818182\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5636363636363636\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5127272727272727\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6472727272727272\n",
      "\t\tAccurary on DEVTEST: 0.5825771324863884\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6254545454545455\n",
      "Epoch 10:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5472727272727272\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5254545454545455\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5818181818181818\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5290909090909091\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5236363636363637\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6218181818181818\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6163636363636363\n",
      "Epoch 11:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.4636363636363636\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5181818181818182\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5709090909090909\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5254545454545455\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5509090909090909\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6236363636363637\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6018181818181818\n",
      "Epoch 12:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5454545454545454\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5236363636363637\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5890909090909091\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.49636363636363634\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5454545454545454\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.62\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6145454545454545\n",
      "Epoch 13:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.46\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5236363636363637\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5745454545454546\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5345454545454545\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5436363636363636\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5781818181818181\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.5890909090909091\n",
      "Epoch 14:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.49272727272727274\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.54\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5781818181818181\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5418181818181819\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5109090909090909\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6090909090909091\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6072727272727273\n",
      "Epoch 15:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.46545454545454545\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5254545454545455\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5709090909090909\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5127272727272727\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5218181818181818\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5890909090909091\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.5872727272727273\n",
      "Epoch 16:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.44545454545454544\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5363636363636364\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5581818181818182\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5872727272727273\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5272727272727272\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6309090909090909\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.5945454545454546\n",
      "Epoch 17:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.4709090909090909\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5127272727272727\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5636363636363636\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5254545454545455\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5072727272727273\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6327272727272727\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6072727272727273\n",
      "Epoch 18:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.4509090909090909\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.54\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5472727272727272\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5363636363636364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.49272727272727274\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6163636363636363\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.5818181818181818\n",
      "Epoch 19:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.48363636363636364\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5054545454545455\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5727272727272728\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5436363636363636\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.48\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6218181818181818\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.5672727272727273\n",
      "Epoch 20:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.4690909090909091\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5327272727272727\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5654545454545454\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.56\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5018181818181818\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5963636363636363\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6036363636363636\n"
     ]
    }
   ],
   "source": [
    "features_pl, accuracy_pl, accuracy_devtest_pl = online_training(train_lst, dev_lst, devtest_lst, features_0, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Binary Features (Perceptron Loss):\n",
      "\tBest Accuracy on DEV: 0.6472727272727272\n",
      "\tBest Accuracy on DEVTEST: 0.5825771324863884\n"
     ]
    }
   ],
   "source": [
    "print(\"Unigram Binary Features (Perceptron Loss):\")\n",
    "print(\"\\tBest Accuracy on DEV: \"+str(accuracy_pl))\n",
    "print(\"\\tBest Accuracy on DEVTEST: \"+str(accuracy_devtest_pl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.44\n",
      "\t\tAccurary on DEVTEST: 0.4029038112522686\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.45454545454545453\n",
      "\t\tAccurary on DEVTEST: 0.41379310344827586\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.4890909090909091\n",
      "\t\tAccurary on DEVTEST: 0.4355716878402904\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.48363636363636364\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.49454545454545457\n",
      "\t\tAccurary on DEVTEST: 0.47549909255898365\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6309090909090909\n",
      "\t\tAccurary on DEVTEST: 0.5317604355716878\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.52\n",
      "Epoch 2:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5327272727272727\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5218181818181818\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5545454545454546\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5545454545454546\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.54\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6509090909090909\n",
      "\t\tAccurary on DEVTEST: 0.5553539019963702\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.5890909090909091\n",
      "Epoch 3:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5472727272727272\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5509090909090909\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5763636363636364\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.58\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5745454545454546\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.649090909090909\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6163636363636363\n",
      "Epoch 4:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5545454545454546\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5527272727272727\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5854545454545454\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5909090909090909\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5836363636363636\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6672727272727272\n",
      "\t\tAccurary on DEVTEST: 0.5862068965517241\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6163636363636363\n",
      "Epoch 5:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5636363636363636\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5618181818181818\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5981818181818181\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6054545454545455\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5909090909090909\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6709090909090909\n",
      "\t\tAccurary on DEVTEST: 0.5862068965517241\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6272727272727273\n",
      "Epoch 6:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5709090909090909\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5727272727272728\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6018181818181818\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.610909090909091\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5909090909090909\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.66\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6309090909090909\n",
      "Epoch 7:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5854545454545454\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5672727272727273\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.610909090909091\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.610909090909091\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6672727272727272\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.64\n",
      "Epoch 8:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5854545454545454\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5672727272727273\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6090909090909091\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6127272727272727\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.610909090909091\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6563636363636364\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6418181818181818\n",
      "Epoch 9:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5836363636363636\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.58\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6072727272727273\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6163636363636363\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6127272727272727\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6581818181818182\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6472727272727272\n",
      "Epoch 10:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5890909090909091\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5872727272727273\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6145454545454545\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6127272727272727\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6036363636363636\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6618181818181819\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6472727272727272\n",
      "Epoch 11:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5981818181818181\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5836363636363636\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6181818181818182\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6181818181818182\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6072727272727273\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6636363636363637\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6545454545454545\n",
      "Epoch 12:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5963636363636363\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5909090909090909\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6127272727272727\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.610909090909091\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6054545454545455\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6618181818181819\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6527272727272727\n",
      "Epoch 13:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5909090909090909\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5927272727272728\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6054545454545455\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.610909090909091\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6036363636363636\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6654545454545454\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6618181818181819\n",
      "Epoch 14:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6018181818181818\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6054545454545455\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6127272727272727\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5963636363636363\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6690909090909091\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6581818181818182\n",
      "Epoch 15:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5963636363636363\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6127272727272727\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6145454545454545\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5963636363636363\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6709090909090909\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6581818181818182\n",
      "Epoch 16:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5890909090909091\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5963636363636363\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6018181818181818\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.610909090909091\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5963636363636363\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6709090909090909\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6545454545454545\n",
      "Epoch 17:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5963636363636363\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5945454545454546\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.610909090909091\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6072727272727273\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5909090909090909\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6690909090909091\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6527272727272727\n",
      "Epoch 18:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5927272727272728\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5981818181818181\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.610909090909091\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5963636363636363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6672727272727272\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6509090909090909\n",
      "Epoch 19:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5945454545454546\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5945454545454546\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6127272727272727\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5981818181818181\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5927272727272728\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6654545454545454\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6563636363636364\n",
      "Epoch 20:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5981818181818181\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5872727272727273\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6090909090909091\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6018181818181818\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5945454545454546\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6636363636363637\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6563636363636364\n"
     ]
    }
   ],
   "source": [
    "features_hl, accuracy_hl, accuracy_devtest_hl = online_training(train_lst, dev_lst, devtest_lst, features_0, labels, hinge=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Binary Features (Hinge Loss):\n",
      "\tBest Accuracy on DEV: 0.6709090909090909\n",
      "\tBest Accuracy on DEVTEST: 0.5862068965517241\n"
     ]
    }
   ],
   "source": [
    "print(\"Unigram Binary Features (Hinge Loss):\")\n",
    "print(\"\\tBest Accuracy on DEV: \"+str(accuracy_hl))\n",
    "print(\"\\tBest Accuracy on DEVTEST: \"+str(accuracy_devtest_hl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0:\n",
      "\tTop 10 features:\n",
      "\t\tlacks: 1.39\n",
      "\t\tlacking: 1.27\n",
      "\t\ttiresome: 1.24\n",
      "\t\tlistless: 1.21\n",
      "\t\tlousy: 1.18\n",
      "\t\tworst: 1.17\n",
      "\t\tunfunny: 1.17\n",
      "\t\tuneven: 1.17\n",
      "\t\tsloppy: 1.17\n",
      "\t\tdepressing: 1.17\n",
      "\tBottom 10 features:\n",
      "\t\twonderful: -0.79\n",
      "\t\tenjoyable: -0.76\n",
      "\t\tnice: -0.75\n",
      "\t\timpressive: -0.72\n",
      "\t\t-RRB-: -0.71\n",
      "\t\tcute: -0.70\n",
      "\t\tlikable: -0.69\n",
      "\t\tbeautifully: -0.66\n",
      "\t\tcharming: -0.66\n",
      "\t\thilarious: -0.66\n",
      "Label 1:\n",
      "\tTop 10 features:\n",
      "\t\tmeans: 0.36\n",
      "\t\tMr: 0.35\n",
      "\t\tWhile: 0.34\n",
      "\t\tnor: 0.33\n",
      "\t\tBig: 0.33\n",
      "\t\tCletis: 0.32\n",
      "\t\tIf: 0.30\n",
      "\t\tword: 0.29\n",
      "\t\tentire: 0.29\n",
      "\t\tYork: 0.28\n",
      "\tBottom 10 features:\n",
      "\t\tenjoy: -0.43\n",
      "\t\tsweet: -0.43\n",
      "\t\tcare: -0.42\n",
      "\t\tperfect: -0.42\n",
      "\t\tbest: -0.41\n",
      "\t\tendearing: -0.40\n",
      "\t\tgood: -0.40\n",
      "\t\tterrific: -0.40\n",
      "\t\texciting: -0.39\n",
      "\t\tflawed: -0.39\n",
      "Label 2:\n",
      "\tTop 10 features:\n",
      "\t\tpleasant: 1.29\n",
      "\t\ttreat: 1.22\n",
      "\t\tthought-provoking: 1.22\n",
      "\t\twonderfully: 1.20\n",
      "\t\ttouching: 1.17\n",
      "\t\tvividly: 1.16\n",
      "\t\tdelight: 1.14\n",
      "\t\twonderful: 1.13\n",
      "\t\tfunniest: 1.10\n",
      "\t\tfeel-good: 1.10\n",
      "\tBottom 10 features:\n",
      "\t\tn't: -1.07\n",
      "\t\tlacks: -1.06\n",
      "\t\tlacking: -1.00\n",
      "\t\thardly: -0.93\n",
      "\t\tlack: -0.92\n",
      "\t\tno: -0.92\n",
      "\t\tworst: -0.92\n",
      "\t\tdevoid: -0.90\n",
      "\t\tfailure: -0.90\n",
      "\t\tnor: -0.87\n"
     ]
    }
   ],
   "source": [
    "d1 = weight_analysis(features_hl, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: With the exception of some fleetingly amusing improvisations by Cedric the Entertainer as Perry 's boss , there is n't a redeeming moment here .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Though only 60 minutes long , the film is packed with information and impressions .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: There 's a solid woman - finding-herself story somewhere in here , but you 'd have to dig pretty deep to uncover it .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: A great ensemble cast ca n't lift this heartfelt enterprise out of the familiar .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Sam Mendes has become valedictorian at the School for Soft Landings and Easy Ways Out .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: There 's just no currency in deriding James Bond for being a clichéd , doddering , misogynistic boy 's club .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Remember the kind of movie we were hoping `` Ecks vs. Sever '' or `` xXx '' was going to be ?\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Inside the film 's conflict-powered plot there is a decent moral trying to get out , but it 's not that , it 's the tension that keeps you in your seat .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Under 15 ?\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: To say this was done better in Wilder 's Some Like It Hot is like saying the sun rises in the east .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: A thinly veiled look at different aspects of Chinese life clashing with each other .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: The ga-zillionth airhead movie about a wife in distress who resorts to desperate measures .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: A gripping , searing portrait of a lost soul trying to find her way through life .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: As unseemly as its title suggests .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: That 's pure PR hype .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: There 's enough melodrama in this Magnolia Primavera to make PTA proud yet director Muccino 's characters are less worthy of Puccini than they are of daytime television .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: It 's a feature-length adaptation of one of those `` Can This Marriage Be Saved ? ''\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: This remake gets all there is to get out of a peculiar premise with promise : Al Pacino loathing Robin Williams .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: A hamfisted romantic comedy that makes our girl the hapless facilitator of an extended cheap shot across the Mason-Dixon line .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Jaglom ... put -LRB- s -RRB- the audience in the privileged position of eavesdropping on his characters\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: ` They ' begins and ends with scenes so terrifying I 'm still stunned .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Not far beneath the surface , this reconfigured tale asks disturbing questions about those things we expect from military epics .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Impostor has a handful of thrilling moments and a couple of good performances , but the movie does n't quite fly .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: It 's mighty tedious for the viewer who has to contend with unpleasant characters , hit-and-miss performances and awkwardly staged scenes .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Skins has a right to yawp , and we have a right to our grains of salt .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: A difficult , absorbing film that manages to convey more substance despite its repetitions and inconsistencies than do most films than are far more pointed and clear .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: The subtle strength of `` Elling '' is that it never loses touch with the reality of the grim situation .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: It will not appeal to the impatient , but those who like long books and movies will admire the way it accumulates power and depth .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Though Catch Me If You Can is n't badly made , the fun slowly leaks out of the movie .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: The only excitement comes when the credits finally roll and you get to leave the theater .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: And that leaves a hole in the center of The Salton Sea .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Walter Hill 's pulpy , stylized boxing melodrama Undisputed nearly overcomes its questionable in-the-ring match-up with solid fight choreography and gritty prison authenticity .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Even if you do n't think -LRB- Kissinger 's -RRB- any more guilty of criminal activity than most contemporary statesmen , he 'd sure make a courtroom trial great fun to watch .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Filmmakers who can deftly change moods are treasures and even marvels .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Scorsese at his best makes gangster films that are equally lovely but also relentlessly brutal and brutally intelligent ; Perdition , meanwhile , reads more like Driving Miss Daisy than GoodFellas .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: If your taste runs to ` difficult ' films you absolutely ca n't miss it .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Let 's hope -- shall we ?\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: There can be no other explanation .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Just an average comedic dateflick but not a waste of time .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: The idea of 49-year-old Roberto Benigni playing the wooden boy Pinocchio is scary enough .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: There 's something with potential here , but the movie decides , like Lavinia , to go the conservative route .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: While the Resident Evil games may have set new standards for thrills , suspense , and gore for video games , the movie really only succeeds in the third of these .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Has all the depth of a wading pool .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Its maker , Steven Spielberg , has n't had so much fun in two decades , since he was schlepping Indiana Jones around the globe in search of a giant misplaced ashtray .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: McConaughey 's fun to watch , the dragons are okay , not much fire in the script .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: If this story must be told and retold -- and indeed it must -- then The Grey Zone is to be lauded for finding a new and ingenious angle .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Some of it is clever , but it is never melodic \\/\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: A stunning and overwhelmingly cogent case for Kissinger as a calculating war criminal .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: A better title , for all concerned , might be Swept Under the Rug .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: What 's next : `` My Mother the Car ? ''\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: A ragbag of promising ideas and failed narrative , of good acting and plain old bad filmmaking .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: More maudlin than sharp .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Oh come on .\n",
      "Gold Standard: 0\n",
      "Prediction: 1\n",
      "\n",
      "\n",
      "Sentence: Would n't one about their famous dad , author of Death in Venice , etc. , be more valuable ?\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: As the latest bid in the TV-to-movie franchise game , I Spy makes its big-screen entry with little of the nervy originality of its groundbreaking small-screen progenitor .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Something akin to a Japanese Alice Through the Looking Glass , except that it seems to take itself far more seriously .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: It haunts , horrifies , startles and fascinates ; it is impossible to look away .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: It takes a strange kind of laziness to waste the talents of Robert Forster , Anne Meara , Eugene Levy , and Reginald VelJohnson all in the same movie .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: The vintage is pure ' 87 , with a halfhearted twist on its cautionary message : Fatal Attraction = do n't have an affair with a nutjob ; Unfaithful = do n't if you 're married to one .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: The tale of Tok -LRB- Andy Lau -RRB- , a sleek sociopath on the trail of O -LRB- Takashi Sorimachi -RRB- , the most legendary of Asian hitmen , is too scattershot to take hold .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Despite impeccable acting ... and a script that takes some rather unexpected -LRB- even , at times , preposterous -RRB- turns , Love is just too , too precious in the end .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Do n't be fooled by the impressive cast list - Eye See You is pure junk .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: It 's a demented kitsch mess -LRB- although the smeary digital video does match the muddled narrative -RRB- , but it 's savvy about celebrity and has more guts and energy than much of what will open this year .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Fancy a real downer ?\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: It 's not without its pleasures , but I 'll stick with The Tune .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Although the level of the comedy declines as the movie proceeds , there 's no denying the fun of watching De Niro and Crystal having fun .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Makes even the claustrophobic on-board quarters seem fun .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: If the movie succeeds in instilling a wary sense of ` there but for the grace of God , ' it is far too self-conscious to draw you deeply into its world .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Scores no points for originality , wit , or intelligence .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Nine Queens is not only than a frighteningly capable debut and genre piece , but also a snapshot of a dangerous political situation on the verge of coming to a head .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Exactly what it claims to be -- a simple diversion for the kids .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: The movie is n't just hilarious : It 's witty and inventive , too , and in hindsight , it is n't even all that dumb .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Although German cooking does not come readily to mind when considering the world 's best cuisine , Mostly Martha could make Deutchland a popular destination for hungry tourists .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: It ca n't decide if it wants to be a mystery\\/thriller , a romance or a comedy .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Funny but perilously slight .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: It seems like I have been waiting my whole life for this movie and now I ca n't wait for the sequel .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: By the miserable standards to which the slasher genre has sunk , ... actually pretty good .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: The Movie could have been made 40 years ago , and parents ' appreciation of it may depend on whether they consider that a good thing .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: A beautifully made piece of unwatchable drivel .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: It 's hard to know whether or not to recommend this film because for every thing it does right there 's at least one and occasionally two things it gets ever so wrong .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Verbinski implements every hack-artist trick to give us the ooky-spookies .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: And I 've decided to leave a light on every night from now on .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Full of witless jokes , dealing in broad stereotypes and outrageously unbelievable scenarios , and saddled with a general air of misogyny\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: The primitive force of this film seems to bubble up from the vast collective memory of the combatants .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Ah yes , and then there 's the music ...\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: It has all the excitement of eating oatmeal .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Exists then as an occasionally insightful acting exercise .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: It 's so good that its relentless , polished wit can withstand not only inept school productions , but even Oliver Parker 's movie adaptation .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: An appealingly juvenile trifle that delivers its share of laughs and smiles .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: The piquant story needs more dramatic meat on its bones .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: While it 's genuinely cool to hear characters talk about early rap records -LRB- Sugar Hill Gang , etc. -RRB- , the constant referencing of hip-hop arcana can alienate even the savviest audiences .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Much as we might be interested in gratuitous sexualization , Haneke has a different objective in mind -- namely the implications of our craving for fake stimulation .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: On the heels of The Ring comes a similarly morose and humorless horror movie that , although flawed , is to be commended for its straight-ahead approach to creepiness .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: As a tolerable diversion , the film suffices ; a Triumph , however , it is not .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Looking aristocratic , luminous yet careworn in Jane Hamilton 's exemplary costumes , Rampling gives a performance that could not be improved upon . '\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: It may seem long at 110 minutes if you 're not a fan , because it includes segments of 12 songs at a reunion concert .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: A painfully funny ode to bad behavior .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: But is that knot from dramatic tension or a symptom of artistic malnutrition ?\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: The movie is for fans who ca n't stop loving anime , and the fanatical excess built into it .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: To my taste , the film 's comic characters come perilously close to being Amoses and Andys for a new generation .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: By the time we learn that Andrew 's Turnabout Is Fair Play is every bit as awful as Borchardt 's Coven , we can enjoy it anyway .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: It 's somewhat clumsy and too lethargically paced -- but its story about a mysterious creature with psychic abilities offers a solid build-up , a terrific climax , and some nice chills along the way .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: If you 're hard up for raunchy college humor , this is your ticket right here .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: We know the plot 's a little crazy , but it held my interest from start to finish .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: All in all , The Count of Monte Cristo is okay , but it is surely no classic , like the novel upon which it is based .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: should be seen at the very least for its spasms of absurdist humor .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: The kind of spectacularly misconceived enterprise that only a sophisticated cinephile could have perpetrated .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: I 'm sure if you 're a Hartley fan , you might enjoy yourself ... Me , I did n't care for it .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: The whole is quite entertaining , but despite its virtues , there is an unsettled feeling to the film .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Determined to be fun , and bouncy , with energetic musicals , the humor did n't quite engage this adult .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Whereas last year 's exemplary Sexy Beast seemed to revitalize the British gangster movie , this equally brutal outing merely sustains it .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Big Fat Waste of Time .\n",
      "Gold Standard: 0\n",
      "Prediction: 1\n",
      "\n",
      "\n",
      "Sentence: Nothing in Waking Up in Reno ever inspired me to think of its inhabitants as anything more than markers in a screenplay .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: The actors are appealing , but Elysian Fields is idiotic and absurdly sentimental .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Pumpkin wants to have it both ways .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: It 's about following your dreams , no matter what your parents think .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: -LRB- Majidi -RRB- makes us think twice about immigrants we see around us every day .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: A taut psychological thriller that does n't waste a moment of its two-hour running time .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Unfortunately , it appears that -LRB- Jackie -RRB- Chan 's US influence is starting to show in his Hong Kong films .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Pumpkin means to be an outrageous dark satire on fraternity life , but its ambitions far exceed the abilities of writer Adam Larson Broder and his co-director , Tony R. Abrams , in their feature debut .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: The French are rather good at this kind of thing , unlike the Americans , who have a passion for Musketeers , only to spoof them .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Prurient playthings aside , there 's little to love about this English trifle .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: For all the writhing and wailing , tears , rage and opium overdoses , there 's no sense of actual passion being washed away in love 's dissolution .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: What the director ca n't do is make either of Val Kilmer 's two personas interesting or worth caring about .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: An occasionally funny , but overall limp , fish-out-of-water story .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: 84 minutes of rolling musical back beat and supercharged cartoon warfare .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: It has charm to spare , and unlike many romantic comedies , it does not alienate either gender in the audience .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: The inhospitability of the land emphasizes the spare precision of the narratives and helps to give them an atavistic power , as if they were tales that had been handed down since the beginning of time .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: columns from Ladies Home Journal ...\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Kept aloft largely by a comically adept ensemble .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Candid Camera on methamphetamines .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Even in its most tedious scenes , Russian Ark is mesmerizing .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Whaley 's determination to immerse you in sheer , unrelenting wretchedness is exhausting .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: The twist that ends the movie is the one with the most emotional resonance , but twists are getting irritating , and this is the kind of material where the filmmakers should be very careful about raising eyebrows .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: It has the ability to offend and put off everyone , but it holds you with its outrageousness .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: If The Count of Monte Cristo does n't transform Caviezel into a movie star , then the game is even more rigged than it was two centuries ago .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Not for the prurient or squeamish , it 's a daring if overlong examination of an idolized culture , self-loathing and sexual politics .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: We have n't seen such hilarity since Say It Is n't So !\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Woody Allen 's latest is an ambling , broad comedy about all there is to love -- and hate -- about the movie biz .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Denis O'Neill 's script avoids the prime sports cliche , a last-second goal to win the championship , but it neglects few others .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: I have no way of knowing exactly how much is exaggeration , but I 've got a creepy feeling that the film is closer to the mark than I want to believe .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: -LRB- Leigh -RRB- lays it on so thick this time that it feels like a suicide race .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: While the script starts promisingly , it loses steam towards the middle and never really develops beyond attacking obvious target .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: I 'll bet the video game is a lot more fun than the film .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: For AIDS and Africa are nothing more than part of the scenery .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: A delirious celebration of the female orgasm .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: It conveys a simple message in a visual style that is willfully overwrought .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: It 's a coming-of-age story we 've all seen bits of in other films -- but it 's rarely been told with such affecting grace and cultural specificity .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Although Huppert 's intensity and focus has a raw exhilaration about it , The Piano Teacher is anything but fun .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Returning aggressively to his formula of dimwitted comedy and even dimmer characters , Sandler , who also executive produces , has made a film that makes previous vehicles look smart and sassy .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Who needs love like this ?\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: A touch of humor or an unexpected plot twist always pulls it back .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: The director knows how to apply textural gloss , but his portrait of sex-as-war is strictly sitcom .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Chokes on its own depiction of upper-crust decorum .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: The lower your expectations , the more you 'll enjoy it .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: The film is based on truth and yet there is something about it that feels incomplete , as if the real story starts just around the corner .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: It offers little beyond the momentary joys of pretty and weightless intellectual entertainment .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: A perplexing example of promise unfulfilled , despite many charming moments .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: ` De Niro ... is a veritable source of sincere passion that this Hollywood contrivance orbits around . '\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: The script kicks in , and Mr. Hartley 's distended pace and foot-dragging rhythms follow .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Open-minded kids -- kids who read , kids who dream -- will be comforted by the way it deals with big issues like death and destiny .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Nothing more substantial than a fitfully clever doodle .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: An unpredictable blend of gal-pal smart talk , romantic comedy and dark tragedy that bites off considerably more than writer\\/director John McKay can swallow .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Generally provides its target audience of youngsters enough stimulating eye and ear candy to make its moral medicine go down .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: An unwise amalgam of Broadcast News and Vibes .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Which is n't to say that it 's the equal of some of its predecessors .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: The plot combines The Blues Brothers and Almost Famous -LRB- but with bears , and a G rating -RRB- , with an excruciating dollop of Disney sentimentality mixed in for good measure .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Sticky sweet sentimentality , clumsy plotting and a rosily myopic view of life in the WWII-era Mississippi Delta undermine this adaptation .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Despite the evocative aesthetics evincing the hollow state of modern love life , the film never percolates beyond a monotonous whine .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: It 's sweet , harmless , dumb , occasionally funny and about as compelling as a fishing show .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Writer\\/director Mark Romanek spotlights the underlying caste system in America .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Hilariously inept and ridiculous .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Yes , Ballistic is silly .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: The film is a contrivance , as artificial as the video games Japanese teens play in a nightclub sequence , but it 's an enjoyable one .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: My thoughts were focused on the characters .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: We root for -LRB- Clara and Paul -RRB- , even like them , though perhaps it 's an emotion closer to pity .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Makes for some truly odd , at times confusing , kids entertainment ... but at least this time there 's some centered storytelling to go along with all the weird stuff .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: This is a story of two misfits who do n't stand a chance alone , but together they are magnificent .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: It will grip even viewers who are n't interested in rap , as it cuts to the heart of American society in an unnerving way .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Manages to be somewhat well-acted , not badly art-directed and utterly unengaging no matter how hard it tries to be thrilling , touching or , yikes , uproarious .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: I felt sad for Lise not so much because of what happens as because she was captured by this movie when she obviously belongs in something lighter and sunnier , by Rohmer , for example .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: It takes talent to make a lifeless movie about the most heinous man who ever lived .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: It 's a scathing portrayal .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: But the power of these -LRB- subjects -RRB- is obscured by the majority of the film that shows a stationary camera on a subject that could be mistaken for giving a public oration , rather than contributing to a film 's narrative .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Whenever its story is n't bogged down by idiocy involving the CIA and a lost U.S. satellite , Hunter -- starring Irwin and his American wife\\/colleague , Terri -- is a movie children should enjoy .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: A full world has been presented onscreen , not some series of carefully structured plot points building to a pat resolution .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Nasty , ugly , pointless and depressing , even if you hate clowns .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: In his first stab at the form , Jacquot takes a slightly anarchic approach that works only sporadically .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: While Undisputed is n't exactly a high , it is a gripping , tidy little movie that takes Mr. Hill higher than he 's been in a while .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: ... routine , harmless diversion and little else .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: The film 's almost unbearable portrait of sadness and grief transcends its specific story to speak to the ways in which need , history and presumption tangle , and sometimes destroy , blood ties .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Historical dramas fused with love triangle is a well worn conceit .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: A sober and affecting chronicle of the leveling effect of loss .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: New Best Friend 's Playboy-mansion presentation of college life is laugh-out-loud ludicrous .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Outer-space buffs might love this film , but others will find its pleasures intermittent .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Every dance becomes about seduction , where backstabbing and betrayals are celebrated , and sex is currency .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: It 's one heck of a character study -- not of Hearst or Davies but of the unique relationship between them .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: The jabs it employs are short , carefully placed and dead-center .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: It 's the perfect kind of film to see when you do n't want to use your brain .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: A twisty , moody slice of Southern Gothic ...\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: As ` chick flicks ' go , this one is pretty miserable , resorting to string-pulling rather than legitimate character development and intelligent plotting .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Dilbert without the right-on satiric humor .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: On the bright side , it contains Jesse Ventura 's best work since the XFL .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: A marvel like none you 've seen .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: If I had been thinking about the visual medium , they would have been doing something wrong .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Ruzowitzky has taken this mothball-y stuff and made a rather sturdy , old-fashioned entertainment out of it .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: It 's refreshing to see a girl-power movie that does n't feel it has to prove anything .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: ... a good , if not entirely fresh , look at war .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Beneath Clouds is a succinct low-budget film whose compelling characters and intelligent script are exactly what was missing from Rabbit-Proof Fence .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: At once half-baked and overheated .\n",
      "Gold Standard: 0\n",
      "Prediction: 1\n",
      "\n",
      "\n",
      "Sentence: We learn a lot about dying coral and see a lot of life on the reef .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: `` Roger Michell -LRB- '' Notting Hill `` -RRB- directs a morality thriller . ''\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: It 's inoffensive , cheerful , built to inspire the young people , set to an unending soundtrack of beach party pop numbers and aside from its remarkable camerawork and awesome scenery , it 's about as exciting as a sunburn .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: If the first Men in Black was money , the second is small change .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Although there are several truly jolting scares , there 's also an abundance of hackneyed dialogue and more silly satanic business than you can shake a severed limb at .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Although Jackson is doubtless reserving the darkest hours for The Return of the King , we long for a greater sense of urgency in the here and now of The Two Towers .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: ... plays like somebody spliced random moments of a Chris Rock routine into what is otherwise a cliche-riddled but self-serious spy thriller .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Feels haphazard , as if the writers mistakenly thought they could achieve an air of frantic spontaneity by simply tossing in lots of characters doing silly stuff and stirring the pot .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Scooby Dooby Doo \\/ And Shaggy too \\/ You both look and sound great .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: While it regards 1967 as the key turning point of the 20th century , and returns again and again to images of dissidents in the streets , it 's alarmingly current .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Half Submarine flick , Half Ghost Story , All in one criminally neglected film\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: Prancing his way through the tailor-made part of a male hooker approaching the end of his vitality , Jagger obviously relishes every self-mocking moment .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: I sympathize with the plight of these families , but the movie does n't do a very good job conveying the issue at hand .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: A broad , melodramatic estrogen opera that 's pretty toxic in its own right .\n",
      "Gold Standard: 0\n",
      "Prediction: 2\n",
      "\n",
      "\n",
      "Sentence: It 's a work by an artist so in control of both his medium and his message that he can improvise like a jazzman .\n",
      "Gold Standard: 2\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: A morose little soap opera about three vapid , insensitive people who take turns hurting each other .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n",
      "Sentence: Van Wilder does n't bring anything new to the proverbial table , but it does possess a coherence absent in recent crass-a-thons like Tomcats , Freddy Got Fingered , and Slackers .\n",
      "Gold Standard: 1\n",
      "Prediction: 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Smith is careful not to make fun of these curious owners of architectural oddities .\n",
      "Gold Standard: 1\n",
      "Prediction: 2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "error_analysis(devtest_lst, devtest, features_hl, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lst_bb = preprocess(train, feature=\"bb\")\n",
    "dev_lst_bb = preprocess(dev, feature=\"bb\")\n",
    "devtest_lst_bb = preprocess(devtest, feature=\"bb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_bb_0 = extract_features(train_lst_bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.4618181818181818\n",
      "\t\tAccurary on DEVTEST: 0.41197822141560797\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.4581818181818182\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.44727272727272727\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5163636363636364\n",
      "\t\tAccurary on DEVTEST: 0.4537205081669691\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.4890909090909091\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5109090909090909\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.5127272727272727\n",
      "Epoch 2:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5690909090909091\n",
      "\t\tAccurary on DEVTEST: 0.49364791288566245\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5436363636363636\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5272727272727272\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5836363636363636\n",
      "\t\tAccurary on DEVTEST: 0.4900181488203267\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5309090909090909\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5363636363636364\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.5363636363636364\n",
      "Epoch 3:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6054545454545455\n",
      "\t\tAccurary on DEVTEST: 0.5045372050816697\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5745454545454546\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5545454545454546\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5963636363636363\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.56\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5581818181818182\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.56\n",
      "Epoch 4:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6145454545454545\n",
      "\t\tAccurary on DEVTEST: 0.5172413793103449\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5963636363636363\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5836363636363636\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6127272727272727\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5854545454545454\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5781818181818181\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.5727272727272728\n",
      "Epoch 5:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6163636363636363\n",
      "\t\tAccurary on DEVTEST: 0.5190562613430127\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6018181818181818\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5890909090909091\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6145454545454545\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5909090909090909\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5818181818181818\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.58\n",
      "Epoch 6:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.62\n",
      "\t\tAccurary on DEVTEST: 0.5281306715063521\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6018181818181818\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5818181818181818\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6090909090909091\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5927272727272728\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5872727272727273\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.5872727272727273\n",
      "Epoch 7:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6236363636363637\n",
      "\t\tAccurary on DEVTEST: 0.5408348457350273\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.610909090909091\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5945454545454546\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6145454545454545\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5963636363636363\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5945454545454546\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.5963636363636363\n",
      "Epoch 8:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6290909090909091\n",
      "\t\tAccurary on DEVTEST: 0.5553539019963702\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.610909090909091\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5945454545454546\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6218181818181818\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5981818181818181\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6\n",
      "Epoch 9:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6345454545454545\n",
      "\t\tAccurary on DEVTEST: 0.5553539019963702\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6127272727272727\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5945454545454546\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6236363636363637\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6127272727272727\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5981818181818181\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6036363636363636\n",
      "Epoch 10:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6327272727272727\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.610909090909091\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6036363636363636\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6254545454545455\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6163636363636363\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6018181818181818\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6036363636363636\n",
      "Epoch 11:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6363636363636364\n",
      "\t\tAccurary on DEVTEST: 0.5462794918330308\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6127272727272727\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6090909090909091\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6290909090909091\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.62\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6054545454545455\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6090909090909091\n",
      "Epoch 12:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6418181818181818\n",
      "\t\tAccurary on DEVTEST: 0.542649727767695\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6127272727272727\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6072727272727273\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6290909090909091\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6181818181818182\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6145454545454545\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6127272727272727\n",
      "Epoch 13:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6472727272727272\n",
      "\t\tAccurary on DEVTEST: 0.5462794918330308\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6163636363636363\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6054545454545455\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6290909090909091\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6163636363636363\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6127272727272727\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6127272727272727\n",
      "Epoch 14:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6472727272727272\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.62\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6218181818181818\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6236363636363637\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6127272727272727\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6145454545454545\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6163636363636363\n",
      "Epoch 15:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6472727272727272\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6218181818181818\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.62\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6272727272727273\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6218181818181818\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6181818181818182\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6163636363636363\n",
      "Epoch 16:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6454545454545455\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6236363636363637\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.62\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6254545454545455\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6163636363636363\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6181818181818182\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6163636363636363\n",
      "Epoch 17:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6381818181818182\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6290909090909091\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6218181818181818\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6236363636363637\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6090909090909091\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6218181818181818\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6181818181818182\n",
      "Epoch 18:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6327272727272727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6272727272727273\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6254545454545455\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6218181818181818\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6090909090909091\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6127272727272727\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.610909090909091\n",
      "Epoch 19:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6345454545454545\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6290909090909091\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6181818181818182\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6254545454545455\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6054545454545455\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.610909090909091\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6090909090909091\n",
      "Epoch 20:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6363636363636364\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6290909090909091\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6145454545454545\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6254545454545455\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6054545454545455\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6090909090909091\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6072727272727273\n"
     ]
    }
   ],
   "source": [
    "features_bb, accuracy_bb, accuracy_devtest_bb = online_training(train_lst_bb, dev_lst_bb, devtest_lst_bb, features_bb_0, labels, hinge=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Binary Features (Hinge Loss):\n",
      "\tBest Accuracy on DEV: 0.6472727272727272\n",
      "\tBest Accuracy on DEVTEST: 0.5462794918330308\n"
     ]
    }
   ],
   "source": [
    "print(\"Bigram Binary Features (Hinge Loss):\")\n",
    "print(\"\\tBest Accuracy on DEV: \"+str(accuracy_bb))\n",
    "print(\"\\tBest Accuracy on DEVTEST: \"+str(accuracy_devtest_bb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0:\n",
      "\tTop 10 features:\n",
      "\t\t('lacks', 'the'): 1.31\n",
      "\t\t('never', 'quite'): 1.26\n",
      "\t\t(\"'s\", 'hardly'): 1.12\n",
      "\t\t('a', 'failure'): 1.11\n",
      "\t\t('lacking', 'in'): 1.08\n",
      "\t\t('a', 'mess'): 1.08\n",
      "\t\t('most', 'offensive'): 1.05\n",
      "\t\t('bad', 'movie'): 1.05\n",
      "\t\t('pretty', 'mediocre'): 1.04\n",
      "\t\t('terrible', 'movie'): 1.03\n",
      "\tBottom 10 features:\n",
      "\t\t('never', 'dull'): -0.65\n",
      "\t\t('not', 'too'): -0.61\n",
      "\t\t('a', 'masterpiece'): -0.58\n",
      "\t\t('certainly', 'does'): -0.58\n",
      "\t\t('funny', 'and'): -0.58\n",
      "\t\t('I', 'liked'): -0.56\n",
      "\t\t('not', 'without'): -0.56\n",
      "\t\t('so', 'well'): -0.54\n",
      "\t\t('good', 'time'): -0.53\n",
      "\t\t(\"n't\", 'feel'): -0.52\n",
      "Label 1:\n",
      "\tTop 10 features:\n",
      "\t\t('Mr', '.'): 0.64\n",
      "\t\t('most', 'part'): 0.54\n",
      "\t\t('an', 'exploration'): 0.50\n",
      "\t\t('elements', '.'): 0.47\n",
      "\t\t('All', 'Fears'): 0.43\n",
      "\t\t(\"'s\", 'time'): 0.43\n",
      "\t\t('anything', 'else'): 0.42\n",
      "\t\t('Chill', \"''\"): 0.41\n",
      "\t\t(\"''\", 'reunion'): 0.41\n",
      "\t\t('Bartlett', \"'s\"): 0.40\n",
      "\tBottom 10 features:\n",
      "\t\t('too', 'much'): -0.37\n",
      "\t\t('could', \"n't\"): -0.36\n",
      "\t\t('too', 'long'): -0.36\n",
      "\t\t(\"'s\", 'best'): -0.35\n",
      "\t\t('as', 'bad'): -0.35\n",
      "\t\t('of', 'hope'): -0.35\n",
      "\t\t('rich', 'and'): -0.35\n",
      "\t\t('see', 'this'): -0.35\n",
      "\t\t('Do', \"n't\"): -0.34\n",
      "\t\t('care', 'about'): -0.34\n",
      "Label 2:\n",
      "\tTop 10 features:\n",
      "\t\t('very', 'best'): 1.18\n",
      "\t\t(\"n't\", 'disappoint'): 1.15\n",
      "\t\t('very', 'funny'): 1.08\n",
      "\t\t('powerful', 'and'): 1.08\n",
      "\t\t('to', 'behold'): 1.07\n",
      "\t\t(',', 'amusing'): 1.07\n",
      "\t\t('never', 'dull'): 1.06\n",
      "\t\t('smart', ','): 1.05\n",
      "\t\t('of', 'laughs'): 1.05\n",
      "\t\t('funny', 'stuff'): 1.04\n",
      "\tBottom 10 features:\n",
      "\t\t('lacks', 'the'): -0.94\n",
      "\t\t('devoid', 'of'): -0.83\n",
      "\t\t('fails', 'to'): -0.78\n",
      "\t\t('never', 'rises'): -0.78\n",
      "\t\t('supposed', 'to'): -0.69\n",
      "\t\t('not', 'very'): -0.65\n",
      "\t\t('may', 'not'): -0.63\n",
      "\t\t('impossible', 'to'): -0.61\n",
      "\t\t(\"n't\", 'much'): -0.61\n",
      "\t\t('painful', 'to'): -0.61\n"
     ]
    }
   ],
   "source": [
    "d2 = weight_analysis(features_bb, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lst_n = preprocess(train, feature=\"normalized\")\n",
    "dev_lst_n = preprocess(dev, feature=\"normalized\")\n",
    "devtest_lst_n = preprocess(devtest, feature=\"normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_n_0 = extract_features(train_lst_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.4490909090909091\n",
      "\t\tAccurary on DEVTEST: 0.42105263157894735\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.4618181818181818\n",
      "\t\tAccurary on DEVTEST: 0.4355716878402904\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.4818181818181818\n",
      "\t\tAccurary on DEVTEST: 0.4537205081669691\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6218181818181818\n",
      "\t\tAccurary on DEVTEST: 0.573502722323049\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6090909090909091\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6236363636363637\n",
      "\t\tAccurary on DEVTEST: 0.5698729582577132\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6272727272727273\n",
      "\t\tAccurary on DEVTEST: 0.573502722323049\n",
      "Epoch 2:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5618181818181818\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5709090909090909\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5690909090909091\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6436363636363637\n",
      "\t\tAccurary on DEVTEST: 0.588021778584392\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6345454545454545\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.64\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6381818181818182\n",
      "Epoch 3:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5872727272727273\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5781818181818181\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5872727272727273\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6545454545454545\n",
      "\t\tAccurary on DEVTEST: 0.5843920145190563\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6418181818181818\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6345454545454545\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.64\n",
      "Epoch 4:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6018181818181818\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5854545454545454\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5909090909090909\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6527272727272727\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6436363636363637\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.64\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6381818181818182\n",
      "Epoch 5:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6054545454545455\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5909090909090909\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6072727272727273\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6581818181818182\n",
      "\t\tAccurary on DEVTEST: 0.5934664246823956\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6509090909090909\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6472727272727272\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6472727272727272\n",
      "Epoch 6:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6145454545454545\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.5981818181818181\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6036363636363636\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6527272727272727\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6472727272727272\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6472727272727272\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6472727272727272\n",
      "Epoch 7:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6309090909090909\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6018181818181818\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.610909090909091\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6581818181818182\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.649090909090909\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.649090909090909\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6509090909090909\n",
      "Epoch 8:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6290909090909091\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6090909090909091\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6127272727272727\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.66\n",
      "\t\tAccurary on DEVTEST: 0.5934664246823956\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6545454545454545\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.649090909090909\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6527272727272727\n",
      "Epoch 9:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6272727272727273\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6127272727272727\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6218181818181818\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6618181818181819\n",
      "\t\tAccurary on DEVTEST: 0.5970961887477314\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6545454545454545\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6581818181818182\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.66\n",
      "Epoch 10:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6345454545454545\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6072727272727273\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6163636363636363\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6581818181818182\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6527272727272727\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.66\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6618181818181819\n",
      "Epoch 11:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6309090909090909\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.610909090909091\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.62\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6581818181818182\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.66\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6563636363636364\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6563636363636364\n",
      "Epoch 12:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6290909090909091\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6181818181818182\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6181818181818182\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6545454545454545\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.66\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6545454545454545\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6563636363636364\n",
      "Epoch 13:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6290909090909091\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6163636363636363\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.62\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.649090909090909\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.66\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6563636363636364\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.66\n",
      "Epoch 14:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6309090909090909\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.62\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.62\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6545454545454545\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.66\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6563636363636364\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6563636363636364\n",
      "Epoch 15:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6381818181818182\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6163636363636363\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6254545454545455\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6509090909090909\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6581818181818182\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6545454545454545\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6581818181818182\n",
      "Epoch 16:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6418181818181818\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6181818181818182\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6290909090909091\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6509090909090909\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6563636363636364\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6545454545454545\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6563636363636364\n",
      "Epoch 17:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6418181818181818\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6181818181818182\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6254545454545455\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.649090909090909\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6545454545454545\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.649090909090909\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6527272727272727\n",
      "Epoch 18:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6381818181818182\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6181818181818182\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.62\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.649090909090909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6509090909090909\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6509090909090909\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6527272727272727\n",
      "Epoch 19:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6381818181818182\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.62\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6218181818181818\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.649090909090909\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6527272727272727\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6527272727272727\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6563636363636364\n",
      "Epoch 20:\n",
      "\t20000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6381818181818182\n",
      "\t40000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6163636363636363\n",
      "\t60000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6181818181818182\n",
      "\t80000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6472727272727272\n",
      "\t100000 examples trained:\n",
      "\t\tAccurary on DEV: 0.6509090909090909\n",
      "\t120000 examples trained:\n",
      "\t\tAccurary on DEV: 0.649090909090909\n",
      "\t120789 examples trained:\n",
      "\t\tAccurary on DEV: 0.6509090909090909\n"
     ]
    }
   ],
   "source": [
    "features_n, accuracy_n, accuracy_devtest_n = online_training(train_lst_n, dev_lst_n, devtest_lst_n, features_n_0, labels, hinge=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Features (Hinge Loss):\n",
      "\tBest Accuracy on DEV: 0.6618181818181819\n",
      "\tBest Accuracy on DEVTEST: 0.5970961887477314\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalized Features (Hinge Loss):\")\n",
    "print(\"\\tBest Accuracy on DEV: \"+str(accuracy_n))\n",
    "print(\"\\tBest Accuracy on DEVTEST: \"+str(accuracy_devtest_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0:\n",
      "\tTop 10 features:\n",
      "\t\tlistless: 1.55\n",
      "\t\tdisappointment: 1.51\n",
      "\t\tlousy: 1.46\n",
      "\t\tunfunny: 1.44\n",
      "\t\tlack: 1.43\n",
      "\t\tpointless: 1.41\n",
      "\t\tfails: 1.39\n",
      "\t\tfailure: 1.38\n",
      "\t\tlackluster: 1.35\n",
      "\t\tinsult: 1.35\n",
      "\tBottom 10 features:\n",
      "\t\trefresh: -1.03\n",
      "\t\tgoodnatured: -0.90\n",
      "\t\tpowerful: -0.88\n",
      "\t\tlikable: -0.85\n",
      "\t\tfascinate: -0.84\n",
      "\t\timpressive: -0.82\n",
      "\t\twonderful: -0.82\n",
      "\t\tentertaining: -0.76\n",
      "\t\tlovely: -0.75\n",
      "\t\tbeautifully: -0.74\n",
      "Label 1:\n",
      "\tTop 10 features:\n",
      "\t\tgreek: 0.72\n",
      "\t\tleft: 0.67\n",
      "\t\tpartner: 0.54\n",
      "\t\tsolondz: 0.53\n",
      "\t\t50s: 0.46\n",
      "\t\twarren: 0.43\n",
      "\t\t1950s: 0.42\n",
      "\t\tmurdock: 0.41\n",
      "\t\tharvard: 0.41\n",
      "\t\tdeuce: 0.41\n",
      "\tBottom 10 features:\n",
      "\t\tflaw: -0.46\n",
      "\t\thole: -0.44\n",
      "\t\tpoignant: -0.44\n",
      "\t\tplayful: -0.43\n",
      "\t\tuneven: -0.43\n",
      "\t\tattractive: -0.42\n",
      "\t\tenjoy: -0.42\n",
      "\t\tperfect: -0.42\n",
      "\t\tabsurd: -0.41\n",
      "\t\texcite: -0.40\n",
      "Label 2:\n",
      "\tTop 10 features:\n",
      "\t\twonderfully: 1.60\n",
      "\t\tvividly: 1.59\n",
      "\t\tdelight: 1.42\n",
      "\t\tpleasant: 1.37\n",
      "\t\tmiracle: 1.30\n",
      "\t\theartfelt: 1.29\n",
      "\t\tproud: 1.26\n",
      "\t\telegant: 1.25\n",
      "\t\tembrace: 1.24\n",
      "\t\tthoughtprovoking: 1.23\n",
      "\tBottom 10 features:\n",
      "\t\tneither: -1.65\n",
      "\t\tlack: -1.52\n",
      "\t\tdevoid: -1.28\n",
      "\t\tnone: -1.22\n",
      "\t\tfailure: -1.21\n",
      "\t\tflat: -1.21\n",
      "\t\thardly: -1.19\n",
      "\t\twaste: -1.14\n",
      "\t\tfails: -1.13\n",
      "\t\tbore: -1.10\n"
     ]
    }
   ],
   "source": [
    "d3 = weight_analysis(features_n, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
